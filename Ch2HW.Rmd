---
title: "HW2"
author: "Olivia D'Souza, Andrew Ricupito"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(stringr)
```

## Question 1 
Work on Lab 1 if you haven’t done so already. Be sure to read the instructions and the
sample submissions carefully before you start. You are expected to reproduce most of
the outputs in Lab 1 by the end of class on Tuesday, Sept 12.

## Question 2
(This will be in Quiz.) Please review the concept of computing p-values 
and think about how to find the p-value of a one-sided (aka. one-tailed) test from t
he p-value of a two-sided (aka. two-tailed) test. Here are some references:

The following questions use the Copier Maintenance data from Problem 1.20 (p.24)
## Question 3: Problem 2.5 (a, b, c, d) (2 pts)

```{r}
#read Copier Maintenance data in
cm <- read.table("ch2dataset.txt", header=F)
colnames(cm) <- c("time", "copiers")
head(cm, 3)
tail(cm, 2) 
```


# a. Estimate the change in the mean service time when the number of copiers serviced increases by one. Use a 90 percent confidence interval. Interpret your confidence interval.Part (a) is asking about the slope. (Why?) 


```{r}

cm.SLR<-lm(time~copiers, data=cm) #estimated linear regression
cm.SLR
summary(cm.SLR) # In order to find the estimated parameter & standard error
critVal <-qt(.95,43) #finds critical value based on 90% confidence int
critVal
confint(cm.SLR, level=0.90) # confirms my math using R software
```

Part A is asking about the slope because it asks for the "change in mean service time (y variable)
when the number of copiers serviced (x variable) increases by one. This is the definition
of the slope since you interpret the value as the change in mean y for one unit increase of x. 

Confidence Interval = est. of b1 ± (critical value)*(standard error of b1)
Confidence Interval =  15.0352 ± (1.681071)*(0.4831)
  15.0352 + ((1.681071)*(0.4831))
  15.0352 - ((1.681071)*(0.4831))

Confidence Interval = (14.22307, 15.84733)
We are 90% confident that the true slope parameter is between 14.22307 and 15.84733. 


# b. Conduct a t test to determine whether or not there is a linear association between X and Y here; control the a risk at .10. State the alternatives, decision rule, and conclusion. What is the P-value of your test? In part (b), clearly layout the hypothesis, compute the test-statistic using relevant formula, compute the p-value, and state your conclusion in the context of the problem. Then, use the software output to confirm your results. (Similar requirement to part a)

```{r}
summary(cm.SLR) #in order to find estimated parameter & standard error of slope
tobs <- (15.0352 - 0)/(0.4831) # confirmed by summary above

p_value= 2*(pt(q = tobs, df=43,lower.tail=FALSE)) # finding p value for 2 tailed test
# p-value = 4.013936e-31

summary(cm.SLR) # software output to confirm our results

```
H0: beta1 = 0
Ha: beta ≠ 0
T-test statistic = tobs = (b1 - 0)/(standard error of b1)
T-test statistic = tobs = (15.0352 - 0)/(0.4831) = 31.12233

Since the alternative hypothesis is two sided, the p-value is calculated as: 

p value = 2 *P(t df >|tobs|), where df = n-2
df = 43, tobs = 31.12233 
p value = 4.013936e-31

At the significance level of alpha = .1, the resulting p-value (4.013936e-31) is smaller than alpha. Therefore, we reject the null hypothesis. The data provides significance evidence that there is a change in slope between copiers and time, or that there is a linear association. 

Software output confirms that the t-statistic value for the test = 31.123 and a p-value of 2e-16. We can reject the null because the p-value is significantly lower than any possible alpha, especially .1. There is evidence to suggest that there is a change in slope between copiers and time, or that there is a linear association. 

#c. Are your results in parts (a) and (b) consistent? Explain.

Yes, from the condfidence interval in part a, we learned that we are 90% confident that the true slope parameter is between 14.22307 and 15.84733. Additionally, in part b, we rejected the null hypothesis (that slope = 0, or no linear association) because p value < alpha, which suggested there was evidence that there was a linear association. These results are consistent because the confidence interval does not include 0, which would signify 
no linear association. 

# d. The manufacturer has suggested that the mean required time should not increase by more than 14 minutes for each additional copier that is serviced on a service call. Conduct a test to decide whether this standard is being satisfied by Tri-City. Control the risk of a Type I error at .05. State the alternatives, decision rule, and conclusion. What is the P-value of the test? 

# In part (d), test Ha: beta1 > 14. (Why?) Clearly state the hypothesis, use software to get necessary intermediate results, compute the test-statistic using relevant formula, compute the p-value, and state your conclusion in the context of the problem


```{r}
summary(cm.SLR) #in order to find estimated parameter & standard error of slope
tobs <- (15.0352 - 14)/(0.4831) #tobs = 2.142828

p_value= 1 - (pt(q = tobs, df=43)) # finding p value for 1 tailed test (right tail)
# p-value = 0.0189143
```
 
 H0: b1 = 14
 Ha: b1 >14  (because we are looking to see if mean required time increases by more than 14 min for each additional copier that is serviced on a service call)
 
T-test statistic = tobs = (b1 - 14)/(standard error of b1)
T-test statistic = tobs = (15.0352 - 14)/(0.4831) = 2.142828

Since the alternative hypothesis is 1 sided, the p-value is calculated as: 
p value = P(t > tobs), where t~t(n-2) 
p value = 0.0189143

At the significance level of alpha = .05, the resulting p-value (0.0189143) is smaller than alpha. Therefore, we  reject the null hypothesis. The data provides significance evidence that the tmean required time increases by more than 14 minutes for each additional copier that is serviced on a service call, which means TriCity is not satisfying their standard.

 
 
## Question 4 (Problem 2.14 a, b)
# In both part a and b, compute the confidence intervals using relevant formula(s). Follow these steps when “formula-based” computation is requested. First, use software to get the intermediate results, such as the  estimated values and their standard errors. Next, plug the intermediate results into the appropriate formula to construct the confidence interval or prediction interval. Then, use software directly to confirm your results. In SPSS, you can save the CI or PI for the predicted y-values to the data table. In R, use function predict() to compute CI or PI for predicted y-values.

#####
Will complete later, no longer confused
#####

# a. Calculating confidence interval by hand
```{r}
# Values needed:
cmmean <- mean(cm$copiers)
```



# b. Calculating confidence interval using R
```{r}
cm.SLR <- lm(time~copiers, data=cm)
confint(cm.SLR, level = 0.95)
```

## Question 5 
Review the example in Lab 1. R users see item 8 in RLab1_SLR.pdf. SPSS users see
p.6 of Lab1_SLR.pdf. Practice drawing the “confidence interval band” and “prediction
interval band” on the scatter plot with the regression line. Turn in a graph using Copier
Maintenance data
```{r}
plot(time~copiers, data=cm, ylim=c(0, 170), pch=20)
abline(cm.SLR$coef)
newx<-seq(0, 12, by=2) #sets up a grid of x values by creating x val sequence by increment 2 
cm.CI<-predict(cm.SLR, newdata=data.frame(copiers=newx), interval="confidence", leve=0.95) #create CI
cm.PI<-predict(cm.SLR, newdata=data.frame(copiers=newx), interval="prediction", leve=0.95) #create PI
lines(newx, cm.CI[,2], lty=2, col=2) #plot x against second column saved from predictor function, lower
lines(newx, cm.CI[,3], lty=2, col=2) #plot x against second column saved from predictor function, upper
lines(newx, cm.PI[,2], lty=3, col=3, lwd=3)
lines(newx, cm.PI[,3], lty=3, col=3, lwd=3)
<<<<<<< HEAD
=======

>>>>>>> a0315b3 (TA is my new bff here's the update)
```

## Question 6 (Problem 2.24 (b, c, d)) 
Hint: Refer to the ANOVA table in the output.

<<<<<<< HEAD
# a. 
Finding Data 
Creating Tables
```{r}
aov(time ~ copiers, data = cm)
SSTO <- sum((cm$copiers - mean(cm$copiers))^2)

# MSR, MSE, and SSc values derived from SS and df values obtained from aov
MSR <- 76960.42
MSE <- (3416.38/43)

SSc <- 45*mean(cm$copiers^2)
SSTOU <- sum(cm$copiers^2)

E_MSR <- mean((resid(cm.SLR))^2)
E_MSE <- var(resid(cm.SLR))
```

ANOVA table modeled after table 2.2:
```{r}
Source_of_Variation <- c("Regression", "Error", "Total")
# SS derived from aov test
SS <- c("SSR = 76960.42", "SSE = 3416.38", str_c("SSTO = ",SSTO))
df <- c("1", "43", "44")
MS <- c(str_c("MSR = ",MSR), str_c("MSE = ",MSE), " ")
E_MS <- c(str_c("E{MSR} = ",E_MSR), str_c("E{MSE} = ",E_MSE), " ")

cm.aov <- data.frame(Source_of_Variation=Source_of_Variation, SS=SS, df=df, MS=MS, E_MS=E_MS)
cm.aov
```

ANOVA table modeled after table 2.3:
```{r}
Source_of_Variation <- c("Regression", "Error", "Total", "Correction for mean", "Total, uncorrected")
# SS derived from aov test
SS <- c("SSR = 76960.42", "SSE = 3416.38", str_c("SSTO = ",SSTO), str_c("SS = ",SSc), str_c("SSTOU = ",SSTOU))
df <- c("1", "43", "44", "1", "45")
MS <- c(str_c("MSR = ",MSR), str_c("MSE = ",MSE), " ", " ", " ")

cm.aov <- data.frame(Source_of_Variation=Source_of_Variation, SS=SS, df=df, MS=MS)
cm.aov
```

=======
>>>>>>> a0315b3 (TA is my new bff here's the update)
#b.In part b, identify the relevant Sum of Squares from the output. Then verify the computation of the F-test, which is already in the output. Clearly layout the hypothesis, compute the test-statistic using relevant formula, compute the p-value, and statement your conclusion in the context of the problem.
```{r}

```

# Question 7
Refer to the Copier Maintenance data. Learn to read basic output of regression analysis
from another software. We will use SPSS output in the midterm exam.

# a. R users: Review handout Reading_SPSS_output.pdf. Compare the SPSS output to the R output in Homework 1, 2 and 3, and match the result. 

I have learned how to read basic output for regression analysis in R and SPSS.


